# The intent of this configuraiton file is to define all the information needed to completely run an experiment.
#
[EXPERIMENT]
#   A formatted csv file decribing the data sets one per line, where the different data types are listed in a dictionary.
#  'PROJECT,SUBJ,SESSION,"{'T1-30:['T1_1.nii.gz','T1_2.nii.gz'],'T2-30':['T2_1.nii.gz']}"
SESSION_DB=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/edited_without_T2_PD_15s_predict_autoworkup_PREDICTHD.csv
# The desired output directory for this experiment
EXPERIMENT=20140219_TEMPLATE
# The base directory where all experiments of this type go
BASE_OUTPUT_DIR=/Shared/sinapse/CACHE
# Components of pipeline to run.  There are some branches of the workflow that are mostly for validation and experimentation.
#   UPPERCASE denotes major pipeline stages: BASELINE -> TEMPLATE -> LONGITUDINAL
#   lowercase denotes stage options, e.g. BASELINE with tissue_classify and/or auxlmk, LONGITUDINAL with segmentation

# WORKFLOW_COMPONENTS=['BASELINE', 'tissue_classify', 'auxlmk', 'TEMPLATE', 'LONGITUDINAL', 'segmentation']
# TODO: FREESURFER
WORKFLOW_COMPONENTS=['BASELINE', 'tissue_classify', 'auxlmk', 'TEMPLATE', 'LONGITUDINAL', 'segmentation']

PREVIOUS_EXPERIMENT=20140219_BASELINE

# The path to the reference atlas space to be used in this analysis by all BRAINSTools
ATLAS_PATH=/Shared/sinapse/sharedopt/20140606_pre/RHEL6/NAMIC-build/ReferenceAtlas-build/Atlas/Atlas_20131115
# The path to the model files to be used by BCD.
# BCDMODELPATH=%(ATLASPATH)s/20111119_BCD


[NIPYPE]
GLOBAL_DATA_SINK_REWRITE=False
#GLOBAL_DATA_SINK_REWRITE=True


[CLUSTER]
# Necessary modules to load for jobs
MODULES=['python/2.7']
## The cluster queue to use for submitting "normal running" jobs.
QUEUE=-q HJ
## The cluster queue to use for submitting "long running" jobs.
QUEUE_LONG=-q HJ
# The QSTAT command for immediate update of values [ use 'qstat' if in doubt ]
QSTAT_IMMEDIATE=qstat
QSTAT_CACHED=qstat
# The QSTAT command for cached update of values ( to take load off of OGE server during heavy job usage ) [ use 'qstat' if in doubt ]
# QSTAT_IMMEDIATE_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_immediate.sh
# QSTAT_CACHED_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_cached.sh


[RHEL6]
# Run on a cluster?
CLUSTER=true
# The prefix to add to all image files in the $(SESSION_DB) to account for different file system mount points
MOUNT_PREFIX=

_GRAPHVIZ_BIN=/usr/bin/graphviz
# Optional:
#    Environment variables to set, e.g. Freesurfer home, etc.
# ENVAR_DICT={'DUMMY':'JustATestEnv'}

# Optional:
#    Define the bin directory for BRAINSTools (if built outside NAMICExternalProjects)
# _BRAINSTOOLS_BIN_DIR=/path/to/BRAINSTools/bin/

# Optional:
#    Define base build directory to use for default section
# _BUILD_DIR=/my/current/NAMIC/build

# Optional:
#    SimpleITK build directory (contains SimpleITK.py and _SimpleITK.so)
# _SIMPLEITK_PYTHON_LIB=/path/to/directory/with/_SimpleITK.so/

# Optional:
#   Nipype package directory
# _NIPYPE_PACKAGE_DIR=/path/to/nipype/

# Optional:
#   if you have a virtualenv this should be the path to the virtualenv directory
VIRTUALENV_DIR=/Shared/sinapse/sharedopt/20140606_pre/RHEL6/python_HD/


[DEFAULT]
# NAMICExternalProjects build tree
_BUILD_DIR=/Shared/sinapse/sharedopt/20140606_pre/RHEL6/NAMIC-build
_ATLAS_PATH=$(_BUILD_DIR)s/ReferenceAtlas-build/Atlas/Atlas_20131115
_BRAINSTOOLS_BIN_DIR=%(_BUILD_DIR)s/bin
_SIMPLEITK_PYTHON_LIB=%(_BUILD_DIR)s/lib
_NIPYPE_PACKAGE_DIR=%(_BUILD_DIR)s/NIPYPE
############## -- You should not need to modify below here. ###########
APPEND_PYTHONPATH=%(_NIPYPE_PACKAGE_DIR)s:%(_SIMPLEITK_PYTHON_LIB)s
APPEND_PATH=%(_BRAINSTOOLS_BIN_DIR)s:%(_SIMPLEITK_PYTHON_LIB)s:%(_GRAPHVIZ_BIN)s
